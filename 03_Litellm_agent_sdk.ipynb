{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "PdKwzEluDBN7"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install openai-agents SDK"
      ],
      "metadata": {
        "id": "PdKwzEluDBN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq openai-agents  \"openai-agents[litellm]\""
      ],
      "metadata": {
        "id": "3QdkOviEB2ay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a67065d-9621-4a90-c186-4d70b7125201"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m112.6/116.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m112.6/116.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.8/116.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.2/661.2 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make your Jupyter Notebook capable of running asynchronous functions."
      ],
      "metadata": {
        "id": "7yD91lz4DIAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "7A5YLi3HCfBV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Google Gemini with LiteLLm and OPENAI-Agent SDK"
      ],
      "metadata": {
        "id": "K3VTUWDaGFcV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function Run Sync"
      ],
      "metadata": {
        "id": "P_zEYQa1kHC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import asyncio\n",
        "\n",
        "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "from google.colab import userdata\n",
        "\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "MODEL = 'gemini/gemini-2.0-flash'\n",
        "GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "def main(model: str, api_key: str):\n",
        "  agent = Agent(\n",
        "      name=\"Assistant\",\n",
        "      instructions=\"You only respond in haikus.\",\n",
        "      model=LitellmModel(model=model, api_key=api_key),\n",
        "\n",
        "  )\n",
        "\n",
        "  result = Runner.run_sync(agent, \"What's the weather in Tokyo?\")\n",
        "  print(result.final_output)\n",
        "\n",
        "\n",
        "main(model=MODEL, api_key=GEMINI_API_KEY)\n",
        "\n"
      ],
      "metadata": {
        "id": "WBT9Z8hE6kEB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7faab309-7fb5-48d3-e008-2ac8d18dcf8a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skies are clear and bright,\n",
            "Gentle breeze through city streets,\n",
            "Warm sun shines today.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Async Function"
      ],
      "metadata": {
        "id": "S7ECiU-f5BAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import asyncio\n",
        "\n",
        "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "from google.colab import userdata\n",
        "\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "MODEL = 'gemini/gemini-2.0-flash'\n",
        "GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "\n",
        "\n",
        "async def main(model: str, api_key: str):\n",
        "  agent = Agent(\n",
        "      name=\"Assistant\",\n",
        "      instructions=\"You only respond in haikus.\",\n",
        "      model=LitellmModel(model=model, api_key=api_key),\n",
        "\n",
        "  )\n",
        "\n",
        "  result = await Runner.run(agent, \"What's the weather in Tokyo?\")\n",
        "  print(result.final_output)\n",
        "\n",
        "\n",
        "asyncio.run(main(model=MODEL, api_key=GEMINI_API_KEY))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-QbKRj7wSzr",
        "outputId": "49506d2b-405b-4ac8-8c63-a3f4e86dda1d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skies are clear and bright,\n",
            "Gentle breeze, a sunny day,\n",
            "Warmth upon the skin.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VfJfUqsH5Mfy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}