{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-6J7HVh3j3b",
        "outputId": "858d8c0d-2671-4f10-e0aa-8dd253d4264b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m164.3/164.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m137.1/137.1 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU openai-agents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from agents import (\n",
        "    Agent,                           # ðŸ¤– Core agent class\n",
        "    Runner,                          # ðŸƒ Runs the agent\n",
        "    AsyncOpenAI,                     # ðŸŒ OpenAI-compatible async client\n",
        "    OpenAIChatCompletionsModel,     # ðŸ§  Chat model interface\n",
        "    function_tool,                   # ðŸ› ï¸ Decorator to turn Python functions into tools\n",
        "    set_default_openai_client,      # âš™ï¸ (Optional) Set default OpenAI client\n",
        "    set_tracing_disabled,           # ðŸš« Disable internal tracing/logging\n",
        ")\n",
        "\n",
        "# ðŸŒ¿ Load environment variables from .env file\n",
        "\n",
        "\n",
        "# ðŸš« Disable tracing for clean output (optional for beginners)\n",
        "\n",
        "\n",
        "# ðŸ› ï¸ 3) Define tools (functions wrapped for tool calling)\n",
        "@function_tool\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"ðŸ§® Exact multiplication (use this instead of guessing math).\"\"\"\n",
        "    return a * b\n",
        "\n",
        "@function_tool\n",
        "def sum(a: int, b: int) -> int:\n",
        "    \"\"\"âž• Exact addition (use this instead of guessing math).\"\"\"\n",
        "    return a + b\n",
        "\n",
        "# ðŸ¤– 4) Create agent and register tools\n",
        "agent: Agent = Agent(\n",
        "    name=\"Assistant\",  # ðŸ§‘â€ðŸ« Agent's identity\n",
        "    instructions=(\n",
        "        \"You are a helpful assistant. \"\n",
        "        \"Always use tools for math questions. Always follow DMAS rule (division, multiplication, addition, subtraction). \"\n",
        "        \"Explain answers clearly and briefly for beginners.\"\n",
        "    ),\n",
        "    model=\"gpt-4.1\",\n",
        "    tools=[multiply, sum],  # ðŸ› ï¸ Register tools here\n",
        ")\n",
        "\n",
        "# ðŸ§ª 5) Run the agent with a prompt (tool calling expected)\n",
        "prompt = \"what is 19 + 23 * 2?\"\n",
        "result = Runner.run_sync(agent, prompt)\n",
        "\n",
        "# ðŸ“¤ Print the final result from the agent\n",
        "print(\"\\nðŸ¤– CALLING AGENT\\n\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGpjFB-i3_o1",
        "outputId": "ad8ef7ec-1cfe-4c4d-d7ab-d327af0be54f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ¤– CALLING AGENT\n",
            "\n",
            "According to the DMAS rule (first multiplication, then addition):\n",
            "\n",
            "1. Multiply 23 Ã— 2 = 46\n",
            "2. Add 19 + 46 = 65\n",
            "\n",
            "So, 19 + 23 Ã— 2 = 65.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "3EaXRqJe4SXP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "SFRL8fYe4b3d"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, ModelSettings, Runner\n",
        "\n",
        "# Create a precise math tutor\n",
        "math_tutor = Agent(\n",
        "    name=\"Math Tutor\",\n",
        "    instructions=\"You are a precise math tutor. Always show your work step by step.\",\n",
        "    model_settings=ModelSettings(\n",
        "        temperature=0.1,  # Very focused\n",
        "        max_tokens=500    # Enough for detailed steps\n",
        "    )\n",
        ")\n",
        "\n",
        "result = Runner.run_sync(math_tutor, \"Solve: 2x + 5 = 13\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81QxvId96dsA",
        "outputId": "18c02dd4-fb35-413a-ce89-3c8b67984ff3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To solve the equation \\(2x + 5 = 13\\), follow these steps:\n",
            "\n",
            "1. **Subtract 5 from both sides** to isolate the term with \\(x\\):\n",
            "\n",
            "   \\[\n",
            "   2x + 5 - 5 = 13 - 5\n",
            "   \\]\n",
            "\n",
            "   Simplifying both sides gives:\n",
            "\n",
            "   \\[\n",
            "   2x = 8\n",
            "   \\]\n",
            "\n",
            "2. **Divide both sides by 2** to solve for \\(x\\):\n",
            "\n",
            "   \\[\n",
            "   \\frac{2x}{2} = \\frac{8}{2}\n",
            "   \\]\n",
            "\n",
            "   Simplifying both sides gives:\n",
            "\n",
            "   \\[\n",
            "   x = 4\n",
            "   \\]\n",
            "\n",
            "Thus, the solution is \\(x = 4\\).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "from dataclasses import dataclass\n",
        "from agents import Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel, set_tracing_disabled, function_tool, RunContextWrapper\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class UserContext:\n",
        "    username: str\n",
        "    email: str | None = None\n",
        "\n",
        "@function_tool()\n",
        "async def search(local_context: RunContextWrapper[UserContext], query: str) -> str:\n",
        "    import time\n",
        "    time.sleep(5)  # Simulating a delay for the search operation\n",
        "    return \"No results found.\"\n",
        "\n",
        "async def special_prompt(special_context: RunContextWrapper[UserContext], agent: Agent[UserContext]) -> str:\n",
        "    # who is user?\n",
        "    # which agent\n",
        "    print(f\"\\nUser: {special_context.context},\\n Agent: {agent.name}\\n\")\n",
        "    return f\"You are a math expert. User: {special_context.context.username}, Agent: {agent.name}. Please assist with math-related queries.\"\n",
        "\n",
        "math_agent: Agent = Agent(name=\"Genius\", instructions=special_prompt, model=\"gpt-4.1\", tools=[search])\n",
        "# [{\"role\": \"system\", \"content\": \"...\"}, {\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]\n",
        "\n",
        "async def call_agent():\n",
        "    # Call the agent with a specific input\n",
        "    user_context = UserContext(username=\"abdullah\")\n",
        "\n",
        "    output = await Runner.run(\n",
        "        starting_agent=math_agent,\n",
        "        input=\"search for the best math tutor in my area\",\n",
        "        context=user_context\n",
        "        )\n",
        "    print(f\"\\n\\nOutput: {output.final_output}\\n\\n\")\n",
        "\n",
        "asyncio.run(call_agent())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLrFUGCM634b",
        "outputId": "864ddf77-a6f1-4811-d88e-200a55568c7f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "User: UserContext(username='abdullah', email=None),\n",
            " Agent: Genius\n",
            "\n",
            "\n",
            "User: UserContext(username='abdullah', email=None),\n",
            " Agent: Genius\n",
            "\n",
            "\n",
            "\n",
            "Output: I couldn't find specific information about the best math tutor in your area. Could you please provide your location (city or ZIP code) so I can narrow down the search and provide better recommendations?\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "    \"\"\"Learn Dynamic Instructions with simple examples.\"\"\"\n",
        "    print(\"ðŸŽ­ Dynamic Instructions: Make Your Agent Adapt\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # ðŸŽ¯ Example 1: Basic Dynamic Instructions\n",
        "    print(\"\\nðŸŽ­ Example 1: Basic Dynamic Instructions\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    def basic_dynamic(context: RunContextWrapper, agent: Agent) -> str:\n",
        "        \"\"\"Basic dynamic instructions function.\"\"\"\n",
        "        return f\"You are {agent.name}. Be helpful and friendly.\"\n",
        "\n",
        "    agent_basic = Agent(\n",
        "        name=\"Dynamic Agent\",\n",
        "        instructions=basic_dynamic,\n",
        "\n",
        "    )\n",
        "\n",
        "    result = Runner.run_sync(agent_basic, \"Hello!\")\n",
        "    print(\"Basic Dynamic Agent:\")\n",
        "    print(result.final_output)\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sibGC__78DIq",
        "outputId": "980e255c-d5b7-4d2e-a598-f1ff14962e90"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ­ Dynamic Instructions: Make Your Agent Adapt\n",
            "==================================================\n",
            "\n",
            "ðŸŽ­ Example 1: Basic Dynamic Instructions\n",
            "----------------------------------------\n",
            "Basic Dynamic Agent:\n",
            "Hi there! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸŽ¯ Example 2: Context-Aware Instructions\n",
        "\n",
        "\n",
        "def context_aware(context: RunContextWrapper, agent: Agent) -> str:\n",
        "    \"\"\"Context-aware instructions based on message count.\"\"\"\n",
        "    message_count = len(getattr(context, 'messages', []))\n",
        "\n",
        "    if message_count == 0:\n",
        "        return \"You are a welcoming assistant. Introduce yourself!\"\n",
        "    elif message_count < 3:\n",
        "        return \"You are a helpful assistant. Be encouraging and detailed.\"\n",
        "    else:\n",
        "        return \"You are an experienced assistant. Be concise but thorough.\"\n",
        "\n",
        "agent_context = Agent(\n",
        "        name=\"Context Aware Agent\",\n",
        "        instructions=context_aware,\n",
        "\n",
        "    )\n",
        "\n",
        "    # Test with multiple messages\n",
        "result1 = Runner.run_sync(agent_context, \"Hello!\")\n",
        "print(\"First message:\")\n",
        "print(result1.final_output)\n",
        "\n",
        "result2 = Runner.run_sync(agent_context, \"Tell me about Python\")\n",
        "print(\"\\nSecond message:\")\n",
        "print(result2.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eQNAAwt85xr",
        "outputId": "0a8dd00b-22a4-4efc-b672-b4e1c960dbd4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First message:\n",
            "Hello! I'm your friendly assistant, here to help with anything you need. How can I assist you today?\n",
            "\n",
            "Second message:\n",
            "Python is a high-level, interpreted programming language known for its clear syntax and readability. Created by Guido van Rossum and first released in 1991, Python emphasizes code readability and simplicity, making it a great choice for both beginners and experienced developers.\n",
            "\n",
            "It supports multiple programming paradigms, including procedural, object-oriented, and functional programming. Python's extensive standard library and thriving ecosystem of third-party packages make it versatile for various applications, such as web development, data analysis, machine learning, automation, and more.\n",
            "\n",
            "Thanks to its community, Python continues to grow and evolve, maintaining its reputation as one of the most popular programming languages in the world.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "def time_based(context: RunContextWrapper, agent: Agent) -> str:\n",
        "    \"\"\"Time-based instructions based on current hour.\"\"\"\n",
        "    current_hour = datetime.datetime.now().hour\n",
        "    print(current_hour)\n",
        "\n",
        "    if 6 <= current_hour < 12:\n",
        "        return f\"You are {agent.name}. Good morning! Be energetic and positive.\"\n",
        "    elif 12 <= current_hour < 17:\n",
        "        return f\"You are {agent.name}. Good afternoon! Be focused and productive.\"\n",
        "    else:\n",
        "        return f\"You are {agent.name}. Good evening! Be calm and helpful.\"\n",
        "\n",
        "agent_time = Agent(\n",
        "        name=\"Time Aware Agent\",\n",
        "        instructions=time_based,\n",
        "    )\n",
        "\n",
        "result = Runner.run_sync(agent_time, \"How are you today?\")\n",
        "print(\"Time-Based Agent:\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvkK1v7F9m3P",
        "outputId": "f0b01557-9ab4-4505-bd12-237adc42c4d3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n",
            "Time-Based Agent:\n",
            "Good evening! I'm here and ready to help. How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # ðŸŽ¯ Example 4: Stateful Instructions (Remembers)\n",
        "print(\"\\nðŸŽ­ Example 4: Stateful Instructions\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "class StatefulInstructions:\n",
        "    \"\"\"Stateful instructions that remember interaction count.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.interaction_count = 0\n",
        "\n",
        "    def __call__(self, context: RunContextWrapper, agent: Agent) -> str:\n",
        "        self.interaction_count += 1\n",
        "\n",
        "        if self.interaction_count == 1:\n",
        "            return \"You are a learning assistant. This is our first interaction - be welcoming!\"\n",
        "        elif self.interaction_count <= 3:\n",
        "            return f\"You are a learning assistant. This is interaction #{self.interaction_count} - build on our conversation.\"\n",
        "        else:\n",
        "            return f\"You are an experienced assistant. We've had {self.interaction_count} interactions - be efficient.\"\n",
        "\n",
        "instruction_gen = StatefulInstructions()\n",
        "\n",
        "agent_stateful = Agent(\n",
        "    name=\"Stateful Agent\",\n",
        "    instructions=instruction_gen,\n",
        "\n",
        ")\n",
        "\n",
        "# Test multiple interactions\n",
        "for i in range(3):\n",
        "    result = Runner.run_sync(agent_stateful, f\"Question {i+1}: Tell me about AI\")\n",
        "    print(f\"Interaction {i+1}:\")\n",
        "    print(result.final_output[:100] + \"...\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIxPv_MS-Ldk",
        "outputId": "621e8b9f-3fb8-4596-991c-db6631c5abf0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸŽ­ Example 4: Stateful Instructions\n",
            "----------------------------------------\n",
            "Interaction 1:\n",
            "Hello and welcome! I'd be delighted to tell you about AI. Artificial Intelligence, or AI, refers to ...\n",
            "\n",
            "Interaction 2:\n",
            "Artificial Intelligence (AI) refers to the simulation of human intelligence in machines designed to ...\n",
            "\n",
            "Interaction 3:\n",
            "AI, or artificial intelligence, refers to the simulation of human intelligence in machines. These sy...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸŽ­ Dynamic Instructions: Make Your Agent Adapt\n",
        "# Simple examples to learn dynamic instructions\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from agents import Agent, Runner, OpenAIChatCompletionsModel, AsyncOpenAI, set_tracing_disabled, RunContextWrapper\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Learn Dynamic Instructions with simple examples.\"\"\"\n",
        "    print(\"ðŸŽ­ Dynamic Instructions: Make Your Agent Adapt\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # ðŸŽ¯ Example 1: Basic Dynamic Instructions\n",
        "    print(\"\\nðŸŽ­ Example 1: Basic Dynamic Instructions\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    def basic_dynamic(context: RunContextWrapper, agent: Agent) -> str:\n",
        "        \"\"\"Basic dynamic instructions function.\"\"\"\n",
        "        return f\"You are {agent.name}. Be helpful and friendly.\"\n",
        "\n",
        "    agent_basic = Agent(\n",
        "        name=\"Dynamic Agent\",\n",
        "        instructions=basic_dynamic,\n",
        "\n",
        "    )\n",
        "\n",
        "    result = Runner.run_sync(agent_basic, \"Hello!\")\n",
        "    print(\"Basic Dynamic Agent:\")\n",
        "    print(result.final_output)\n",
        "\n",
        "    # ðŸŽ¯ Example 2: Context-Aware Instructions\n",
        "    print(\"\\nðŸŽ­ Example 2: Context-Aware Instructions\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    def context_aware(context: RunContextWrapper, agent: Agent) -> str:\n",
        "        \"\"\"Context-aware instructions based on message count.\"\"\"\n",
        "        message_count = len(getattr(context, 'messages', []))\n",
        "\n",
        "        if message_count == 0:\n",
        "            return \"You are a welcoming assistant. Introduce yourself!\"\n",
        "        elif message_count < 3:\n",
        "            return \"You are a helpful assistant. Be encouraging and detailed.\"\n",
        "        else:\n",
        "            return \"You are an experienced assistant. Be concise but thorough.\"\n",
        "\n",
        "    agent_context = Agent(\n",
        "        name=\"Context Aware Agent\",\n",
        "        instructions=context_aware,\n",
        "        model=model\n",
        "    )\n",
        "\n",
        "    # Test with multiple messages\n",
        "    result1 = Runner.run_sync(agent_context, \"Hello!\")\n",
        "    print(\"First message:\")\n",
        "    print(result1.final_output)\n",
        "\n",
        "    result2 = Runner.run_sync(agent_context, \"Tell me about Python\")\n",
        "    print(\"\\nSecond message:\")\n",
        "    print(result2.final_output)\n",
        "\n",
        "    # ðŸŽ¯ Example 3: Time-Based Instructions\n",
        "    print(\"\\nðŸŽ­ Example 3: Time-Based Instructions\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    import datetime\n",
        "\n",
        "    def time_based(context: RunContextWrapper, agent: Agent) -> str:\n",
        "        \"\"\"Time-based instructions based on current hour.\"\"\"\n",
        "        current_hour = datetime.datetime.now().hour\n",
        "\n",
        "        if 6 <= current_hour < 12:\n",
        "            return f\"You are {agent.name}. Good morning! Be energetic and positive.\"\n",
        "        elif 12 <= current_hour < 17:\n",
        "            return f\"You are {agent.name}. Good afternoon! Be focused and productive.\"\n",
        "        else:\n",
        "            return f\"You are {agent.name}. Good evening! Be calm and helpful.\"\n",
        "\n",
        "    agent_time = Agent(\n",
        "        name=\"Time Aware Agent\",\n",
        "        instructions=time_based,\n",
        "        model=model\n",
        "    )\n",
        "\n",
        "    result = Runner.run_sync(agent_time, \"How are you today?\")\n",
        "    print(\"Time-Based Agent:\")\n",
        "    print(result.final_output)\n",
        "\n",
        "    # ðŸŽ¯ Example 4: Stateful Instructions (Remembers)\n",
        "    print(\"\\nðŸŽ­ Example 4: Stateful Instructions\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    class StatefulInstructions:\n",
        "        \"\"\"Stateful instructions that remember interaction count.\"\"\"\n",
        "        def __init__(self):\n",
        "            self.interaction_count = 0\n",
        "\n",
        "        def __call__(self, context: RunContextWrapper, agent: Agent) -> str:\n",
        "            self.interaction_count += 1\n",
        "\n",
        "            if self.interaction_count == 1:\n",
        "                return \"You are a learning assistant. This is our first interaction - be welcoming!\"\n",
        "            elif self.interaction_count <= 3:\n",
        "                return f\"You are a learning assistant. This is interaction #{self.interaction_count} - build on our conversation.\"\n",
        "            else:\n",
        "                return f\"You are an experienced assistant. We've had {self.interaction_count} interactions - be efficient.\"\n",
        "\n",
        "    instruction_gen = StatefulInstructions()\n",
        "\n",
        "    agent_stateful = Agent(\n",
        "        name=\"Stateful Agent\",\n",
        "        instructions=instruction_gen,\n",
        "        model=model\n",
        "    )\n",
        "\n",
        "    # Test multiple interactions\n",
        "    for i in range(3):\n",
        "        result = Runner.run_sync(agent_stateful, f\"Question {i+1}: Tell me about AI\")\n",
        "        print(f\"Interaction {i+1}:\")\n",
        "        print(result.final_output[:100] + \"...\")\n",
        "        print()\n",
        "\n",
        "    # ðŸŽ¯ Example 5: Exploring Context and Agent\n",
        "    print(\"\\nðŸŽ­ Example 5: Exploring Context and Agent\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    def explore_context_and_agent(context: RunContextWrapper, agent: Agent) -> str:\n",
        "        \"\"\"Explore what's available in context and agent.\"\"\"\n",
        "        # Access conversation messages\n",
        "        messages = getattr(context, 'messages', [])\n",
        "        message_count = len(messages)\n",
        "\n",
        "        # Access agent properties\n",
        "        agent_name = agent.name\n",
        "        tool_count = len(agent.tools)\n",
        "\n",
        "        return f\"\"\"You are {agent_name} with {tool_count} tools.\n",
        "        This is message #{message_count} in our conversation.\n",
        "        Be helpful and informative!\"\"\"\n",
        "\n",
        "    agent_explorer = Agent(\n",
        "        name=\"Context Explorer\",\n",
        "        instructions=explore_context_and_agent,\n",
        "        model=model\n",
        "    )\n",
        "\n",
        "    result = Runner.run_sync(agent_explorer, \"What can you tell me about yourself?\")\n",
        "    print(\"Context Explorer Agent:\")\n",
        "    print(result.final_output)\n",
        "\n",
        "    print(\"\\nðŸŽ‰ You've learned Dynamic Instructions!\")\n",
        "    print(\"ðŸ’¡ Try changing the functions and see what happens!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "9C0GbV7F71-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nðŸŽ­ Example 5: Exploring Context and Agent\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "def explore_context_and_agent(context: RunContextWrapper, agent: Agent) -> str:\n",
        "  \"\"\"Explore what's available in context and agent.\"\"\"\n",
        "  # Access conversation messages\n",
        "  messages = getattr(context, 'messages', [])\n",
        "  message_count = len(messages)\n",
        "\n",
        "  # Access agent properties\n",
        "  agent_name = agent.name\n",
        "  tool_count = len(agent.tools)\n",
        "\n",
        "  return f\"\"\"You are {agent_name} with {tool_count} tools.\n",
        "  This is message #{message_count} in our conversation.\n",
        "  Be helpful and informative!\"\"\"\n",
        "\n",
        "agent_explorer = Agent(\n",
        "  name=\"Context Explorer\",\n",
        "  instructions=explore_context_and_agent,\n",
        ")\n",
        "\n",
        "result = Runner.run_sync(agent_explorer, \"What can you tell me about yourself?\")\n",
        "print(\"Context Explorer Agent:\")\n",
        "print(result.final_output)\n",
        "\n",
        "print(\"\\nðŸŽ‰ You've learned Dynamic Instructions!\")\n",
        "print(\"ðŸ’¡ Try changing the functions and see what happens!\")\n",
        "\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9KKnBit_GHd",
        "outputId": "ac6f841e-c643-4ad6-a5d3-1bd9d20b2ad1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸŽ­ Example 5: Exploring Context and Agent\n",
            "----------------------------------------\n",
            "Context Explorer Agent:\n",
            "Sure! I'm Context Explorer, here to help answer your questions and provide information on a wide range of topics. My goal is to assist you with clear, concise, and accurate responses. How can I help you today?\n",
            "\n",
            "ðŸŽ‰ You've learned Dynamic Instructions!\n",
            "ðŸ’¡ Try changing the functions and see what happens!\n",
            "ðŸŽ­ Dynamic Instructions: Make Your Agent Adapt\n",
            "==================================================\n",
            "\n",
            "ðŸŽ­ Example 1: Basic Dynamic Instructions\n",
            "----------------------------------------\n",
            "Basic Dynamic Agent:\n",
            "Hi there! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner, trace\n",
        "import asyncio\n",
        "\n",
        "from agents import Agent, Runner, trace\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(name=\"Joke generator\", instructions=\"Tell funny jokes.\")\n",
        "\n",
        "    with trace(\"Joke workflow\"):\n",
        "        first_result = await Runner.run(agent, \"Tell me a joke\")\n",
        "        second_result = await Runner.run(agent, f\"Rate this joke: {first_result.final_output}\")\n",
        "        print(f\"Joke: {first_result.final_output}\")\n",
        "        print(f\"Rating: {second_result.final_output}\")\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSyCb6WWANwH",
        "outputId": "0f6fed5e-46f7-45b9-be83-882a7624cffd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Joke: Why don't scientists trust atoms?\n",
            "\n",
            "Because they make up everything!\n",
            "Rating: That's a classic! I'd give it an 8 out of 10. It's clever and scientific humor always gets a good chuckle.\n"
          ]
        }
      ]
    }
  ]
}