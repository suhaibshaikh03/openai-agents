{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BI6R7gipsbaL",
        "outputId": "e5002b7b-9bca-417f-bcca-d4ac009319f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.2/68.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.7/165.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install openai-agents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "ye1LNLXusgyA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"]=userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "zxOhcqOBsi9x"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "\n",
        "from agents import Agent, ItemHelpers, Runner, trace\n",
        "\n",
        "\"\"\"\n",
        "This example shows the parallelization pattern. We run the agent three times in parallel, and pick\n",
        "the best result.\n",
        "\"\"\"\n",
        "\n",
        "spanish_agent = Agent(\n",
        "    name=\"spanish_agent\",\n",
        "    instructions=\"You translate the user's message to Spanish\",\n",
        ")\n",
        "\n",
        "translation_picker = Agent(\n",
        "    name=\"translation_picker\",\n",
        "    instructions=\"You pick the best Spanish translation from the given options.\",\n",
        ")\n",
        "\n",
        "\n",
        "async def main():\n",
        "    msg = input(\"Hi! Enter a message, and we'll translate it to Spanish.\\n\\n\")\n",
        "\n",
        "    # Ensure the entire workflow is a single trace\n",
        "    with trace(\"Parallel translation\"):\n",
        "        res_1, res_2, res_3 = await asyncio.gather(\n",
        "            Runner.run(\n",
        "                spanish_agent,\n",
        "                msg,\n",
        "            ),\n",
        "            Runner.run(\n",
        "                spanish_agent,\n",
        "                msg,\n",
        "            ),\n",
        "            Runner.run(\n",
        "                spanish_agent,\n",
        "                msg,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        outputs = [\n",
        "            ItemHelpers.text_message_outputs(res_1.new_items),\n",
        "            ItemHelpers.text_message_outputs(res_2.new_items),\n",
        "            ItemHelpers.text_message_outputs(res_3.new_items),\n",
        "        ]\n",
        "\n",
        "        translations = \"\\n\\n\".join(outputs)\n",
        "        print(f\"\\n\\nTranslations:\\n\\n{translations}\")\n",
        "\n",
        "        best_translation = await Runner.run(\n",
        "            translation_picker,\n",
        "            f\"Input: {msg}\\n\\nTranslations:\\n{translations}\",\n",
        "        )\n",
        "\n",
        "    print(\"\\n\\n-----\")\n",
        "\n",
        "    print(f\"Best translation: {best_translation.final_output}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBYrL79xsk2R",
        "outputId": "6cbd718e-1ab8-4cee-a6a8-caededa01e53"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi! Enter a message, and we'll translate it to Spanish.\n",
            "\n",
            "how are you\n",
            "\n",
            "\n",
            "Translations:\n",
            "\n",
            "¿Cómo estás?\n",
            "\n",
            "¿Cómo estás?\n",
            "\n",
            "¿Cómo estás?\n",
            "\n",
            "\n",
            "-----\n",
            "Best translation: All options are the same, and they are correct. The translation is: \n",
            "\n",
            "¿Cómo estás?\n"
          ]
        }
      ]
    }
  ]
}